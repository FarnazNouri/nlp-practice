{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36016251",
   "metadata": {},
   "source": [
    "# Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95850ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1 = ' my num is 123456789 and you are age (50)ask a lot of questions addD_45@gmail.com 4657008755 donndh I dont want to give you my number (123)-455-2333,email hgujk_@gmk.ca do you really wanna know? 234423424 ok: 333-544-6655 order #23449 and order no 3444 is not delivered order 778'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = '\\d{9}| \\(\\d{3}\\)-\\d{3}-\\d{4}| \\d{3}-\\d{3}-\\d{4}'\n",
    "matches = re.findall(phone, chat1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbffd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = '[a-z0-9A-Z_]*@[a-z0-9A-Z]*\\.[a-zA-Z]*'\n",
    "matches = re.findall(email, chat1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84220c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'order[^\\d]*(\\d*)'\n",
    "matches = re.findall(pattern, chat1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki ='''\n",
    "Born\tThomas Jeffrey Hanks\n",
    "July 9, 1956 (age 69)\n",
    "Concord, California, U.S.\n",
    "Citizenship\tUnited States\n",
    "Greece (since 2020)[1]\n",
    "Alma mater\tChabot College\n",
    "Occupations\t\n",
    "Actor filmmaker\n",
    "Years active\t1977–present\n",
    "Works\tFull list\n",
    "Spouses\t\n",
    "Samantha Lewes\n",
    "​\n",
    "​(m. 1978; div. 1987)​\n",
    "Rita Wilson ​(m. 1988)​\n",
    "Children\t4, including Colin and Chet\n",
    "Relatives\t\n",
    "Jim Hanks (brother)\n",
    "Larry Hanks (brother)\n",
    "Lincoln family (through Nancy Hanks)\n",
    "Awards\tFull list\n",
    "Signature\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'age (\\d+)'\n",
    "matches = re.findall(pattern,wiki)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'Born(.*)'\n",
    "matches = re.findall(pattern,wiki)\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'Born.*\\n(.*)\\(age'\n",
    "re.findall(pattern, wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4a380",
   "metadata": {},
   "source": [
    "### 1. Extract all twitter handles from following text. Twitter handle is the text that appears after https://twitter.com/ and is a single word. Also it contains only alpha numeric characters i.e. A-Z a-z , o to 9 and underscore _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36596c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Follow our leader Elon musk on twitter here: https://twitter.com/elonmusk, more information \n",
    "on Tesla's products can be found at https://www.tesla.com/. Also here are leading influencers \n",
    "for tesla related news,\n",
    "https://twitter.com/teslarati\n",
    "https://twitter.com/dummy_tesla\n",
    "https://twitter.com/dummy_2_tesla\n",
    "'''\n",
    "pattern = 'https:\\/\\/twitter\\.com\\/([\\_a-z0-9]*)' # todo: type your regex here\n",
    "\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14437d1",
   "metadata": {},
   "source": [
    "### 2. Extract Concentration Risk Types. It will be a text that appears after \"Concentration Risk:\", In below example, your regex should extract these two strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "text = '''\n",
    "Concentration of Risk: Credit Risk\n",
    "Financial instruments that potentially subject us to a concentration of credit risk consist of cash, cash equivalents, marketable securities,\n",
    "restricted cash, accounts receivable, convertible note hedges, and interest rate swaps. Our cash balances are primarily invested in money market funds\n",
    "or on deposit at high credit quality financial institutions in the U.S. These deposits are typically in excess of insured limits. As of September 30, 2021\n",
    "and December 31, 2020, no entity represented 10% or more of our total accounts receivable balance. The risk of concentration for our convertible note\n",
    "hedges and interest rate swaps is mitigated by transacting with several highly-rated multinational banks.\n",
    "Concentration of Risk: Supply Risk\n",
    "We are dependent on our suppliers, including single source suppliers, and the inability of these suppliers to deliver necessary components of our\n",
    "products in a timely manner at prices, quality levels and volumes acceptable to us, or our inability to efficiently manage these components from these\n",
    "suppliers, could have a material adverse effect on our business, prospects, financial condition and operating results.\n",
    "'''\n",
    "pattern = 'Concentration of Risk:([ a-z0-9A-Z]*)' # todo: type your regex here\n",
    "\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e799d9b",
   "metadata": {},
   "source": [
    "### 3. Companies in europe reports their financial numbers of semi annual basis and you can have a document like this. To exatract quarterly and semin annual period you can use a regex as shown below\n",
    "\n",
    "Hint: you need to use (?:) here to match everything enclosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Tesla's gross cost of operating lease vehicles in FY2021 Q1 was $4.85 billion.\n",
    "BMW's gross cost of operating vehicles in FY2021 S1 was $8 billion.\n",
    "'''\n",
    "\n",
    "pattern = 'FY\\d{4} (?:Q[1-4]|S[1-2])' # todo: type your regex here\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e23eb",
   "metadata": {},
   "source": [
    "### 4. Extract only financial numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Tesla's gross cost of operating lease vehicles in FY2021 Q1 was $4.85 billion. \n",
    "In previous quarter i.e. FY2020 Q4 it was $3 billion.\n",
    "'''\n",
    "\n",
    "pattern = '\\$[1-9\\.]+'\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61842113",
   "metadata": {},
   "source": [
    "### 5. Extract periods and financial numbers both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Tesla's gross cost of operating lease vehicles in FY2021 Q1 was $4.85 billion. \n",
    "In previous quarter i.e. FY2020 Q4 it was $3 billion.\n",
    "'''\n",
    "pattern = 'FY(\\d{4} Q[1-4])[^\\$]+\\$([0-9\\.]+)'\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367022c",
   "metadata": {},
   "source": [
    "## re.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Tesla's gross cost of operating lease vehicles in FY2021 Q1 was $4.85 billion. \n",
    "In previous quarter i.e. FY2020 Q4 it was $3 billion.\n",
    "'''\n",
    "pattern = 'FY(\\d{4} Q[1-4])[^\\$]+\\$([0-9\\.]+)'\n",
    "\n",
    "matches = re.search(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef5461",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576dc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66380e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93bc57",
   "metadata": {},
   "source": [
    "## Sentence tokenization using spacy (Object Oriented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Dr. Strange loves pav nouri of united states. Ali loves new jersey\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfd20e",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(\"Dr. Strange loves pav nouri of united states. Ali loves new jersey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f966685",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"Dr. Strange loves pav nouri of united states. Ali loves new jersey\")\n",
    "for tokens in doc:\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('''\"Let's got to N.Y.!\"''')\n",
    "for tokens in doc:\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ea7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tony gave two $ to peter\")\n",
    "token0 = doc[0]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token0.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30678f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc548ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "token0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2 = doc[2]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf520d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token3 = doc[3]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95707f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e37fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token,'==>', 'index:', token.i, 'is_alpha:', token.is_alpha,\n",
    "          'is_punct:', token.is_punct,\n",
    "          'like_num:', token.like_num,\n",
    "          'is_currency:', token.is_currency,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8db27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('students.txt') as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaea1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "emails = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bee8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH\n",
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"}\n",
    "])\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde196c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza. Ali is here.\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54515c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza. Dr. Ali is here.\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6973e",
   "metadata": {},
   "source": [
    "\n",
    "### Collecting dataset websites from a book paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "data_web = [token.text for token in doc if token.like_url]\n",
    "data_web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93310f76",
   "metadata": {},
   "source": [
    "### Figure out all transactions from this text with amount and currency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tony gave two $ to Peter, Bruce gave 500 € to Steve\")\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bd944",
   "metadata": {},
   "source": [
    "# NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a19b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad004bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
    "for token in doc:\n",
    "    print(token,'|', token.pos_,'|', token.lemma_,'|', token.tag_,'|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96478938",
   "metadata": {},
   "source": [
    "## Ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Tesla Inc is going to acquire Twitter Inc for $45 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))\n",
    "\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab298da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39086ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d0236",
   "metadata": {},
   "source": [
    "## Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "s1 = Span(doc, 0, 1, label= \"ORG\")\n",
    "s2 = Span(doc, 5, 6, label=\"ORG\")\n",
    "doc.set_ents([s1,s2], default='unmodified')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, '|', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39ca17",
   "metadata": {},
   "source": [
    "### If I use blank pipeline I won't have the same result as when I use \"en_core_web_sm\" pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,'|', token.pos_,'|', token.lemma_,'|', token.tag_,'|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a4658",
   "metadata": {},
   "source": [
    "## Stemming and Lammatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c04f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating', 'Eat', 'ate', 'eat', 'ability', 'meeting', 'rafting', 'better']\n",
    "for word in words:\n",
    "    print(word, '|', stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56427d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"eating Eat ate eat ability meeting rafting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_, '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhusted\")\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384eaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c9165",
   "metadata": {},
   "source": [
    "## 'attribute_ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc53f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{\"Text\":\"Bro\"}],[{\"Text\":\"Brah\"}]], {\"LEMMA\":\"Brother\"})\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhusted\")\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb97cc",
   "metadata": {},
   "source": [
    "## POS -> Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53803027",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Farnaz flew to Mars and he ate pizza over there. Wow! she is always hungry\")\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_, '|',token.pos_,'|', token.tag_, spacy.explain(token.tag_))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('''Some text\" could refer to several things, including placeholder text used in design, various forms of written content, or even internet abbreviations. \"Lorem ipsum\", for example, is a common placeholder text used to demonstrate the visual form of a design. Additionally, \"text\" can encompass a wide range of written materials, from books and articles to scripts, songs, and even visual elements like advertisements. Finally, in online communication, abbreviations like \"LOL\", \"FYI\", and \"ASAP\" are frequently used to shorten messages''')\n",
    "filtered_token = []\n",
    "for token in doc:\n",
    "    if token.pos_ not in ['SPACE', 'X', 'PUNCT']:\n",
    "        filtered_token.append(token)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ca411",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.vocab[100].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text,'|',v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da1e25",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "#### Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "Write a short note on the words that have different base words using stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686d0dc",
   "metadata": {},
   "source": [
    "##### Run this cell to import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let import necessary libraries and create the object\n",
    "\n",
    "#for nltk\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#downloading all neccessary packages related to nltk\n",
    "nltk.download('all')\n",
    "\n",
    "\n",
    "#for spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lemmatization in spacy\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "for word in lst_words:\n",
    "    print(word,'|',stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bad209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization:\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28509b3",
   "metadata": {},
   "source": [
    "## important exercises\n",
    "### Exercise2:\n",
    "\n",
    "#### convert the given text into it's base form using both stemming and lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2470d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "words = []\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    word = token.lemma_\n",
    "    words.append(word)\n",
    "\n",
    "final_base_text = ' '.join(words)\n",
    "print(final_base_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d76e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "\n",
    "#step1: Word tokenizing\n",
    "all_word_token = nltk.word_tokenize(text)\n",
    "\n",
    "#step2: getting the base from each token using stemmer\n",
    "all_base_words = []\n",
    "\n",
    "for token in all_word_token:\n",
    "    base = stemmer.stem(token)\n",
    "    all_base_words.append(base)\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()\n",
    "final_base_text = ' '.join(all_base_words)\n",
    "print(final_base_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c4103",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Extract features from raw data\n",
    "\n",
    "### Approches to convert text into vector:\n",
    "- One hot encoder\n",
    " - Lable encoding\n",
    "- Bag of words\n",
    "- TF-IDF\n",
    "- Word Embedding\n",
    "\n",
    "One hot encoding and label encoding won't be used in machine learning nowadays:\n",
    "Not good for similar words like(help, assistance)\n",
    "Use a lot of computational resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112c2a8",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "It uses countVectorizer\n",
    "count of words in the article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb4e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 5, 'hatwa': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer()\n",
    "v.fit([\"Thor hatwa is looking for a job\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533903a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc52d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  category\n",
      "0  Watching Schrödinger's Cat Die University of C...   SCIENCE\n",
      "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
      "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
      "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
      "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME\n",
      "(12695, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/codebasics/nlp-tutorials/main/11_bag_of_n_grams/news_dataset.json\"\n",
    "df = pd.read_json(url)  \n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3801abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fad4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 1381\n",
    "df_business = df[df.category=='BUSINESS'].sample(min_samples, random_state=2022)\n",
    "df_sports = df[df.category=='SPORTS'].sample(min_samples, random_state=2022)\n",
    "df_crime = df[df.category=='CRIME'].sample(min_samples, random_state=2022)\n",
    "df_science = df[df.category=='SCIENCE'].sample(min_samples, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712398a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_business, df_sports, df_crime, df_science], axis=0)\n",
    "df_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be9a90",
   "metadata": {},
   "source": [
    "Convert Categories to the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e46ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num  \n",
       "11967             0  \n",
       "2912              0  \n",
       "3408              0  \n",
       "502               0  \n",
       "5279              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['category_num'] = df_balanced.category.map(\n",
    "    {\n",
    "        'BUSINESS' : 0,\n",
    "        'SPORTS' : 1,\n",
    "        'CRIME' : 2,\n",
    "        'SCIENCE': 3\n",
    "}\n",
    ")\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2996b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7589     Ovulating Women Prefer Images of Penetration O...\n",
       "10442    Scientists Discover Spooky Influence On Baby N...\n",
       "8792     Olympic Race Walker Steps Up To Propose To His...\n",
       "1733     Beloved Bipedal Bear Named Pedals Believed Kil...\n",
       "2526     Elizabeth Smart Gave Birth To Baby Girl, Fathe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.text,\n",
    "    df_balanced.category_num,\n",
    "    test_size= 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify=df_balanced.category_num\n",
    ")\n",
    "print(X_train.shape)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e786def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_num\n",
       "3    1105\n",
       "2    1105\n",
       "0    1105\n",
       "1    1104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064aed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8814574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       276\n",
      "           1       0.93      0.80      0.86       277\n",
      "           2       0.83      0.90      0.86       276\n",
      "           3       0.90      0.80      0.85       276\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.85      0.84      0.84      1105\n",
      "weighted avg       0.85      0.84      0.84      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37f3437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       276\n",
      "           1       0.95      0.74      0.83       277\n",
      "           2       0.82      0.88      0.85       276\n",
      "           3       0.92      0.78      0.84       276\n",
      "\n",
      "    accuracy                           0.82      1105\n",
      "   macro avg       0.85      0.82      0.83      1105\n",
      "weighted avg       0.85      0.82      0.83      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85965b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     African Nation Slaps Exxon With Fine Nearly 7 ...\n",
       "608      These Cringe-Worthy Stories Show It Can Be Har...\n",
       "11172    LISTEN: The Accidental Discovery That Proved T...\n",
       "1346     Build Loyalty -- The Cost -- $00.00 Remember y...\n",
       "1356     Man Killed By Michigan Police Wasn't Targeting...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd2bad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     0\n",
       "608      3\n",
       "11172    3\n",
       "1346     0\n",
       "1356     2\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5712804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 0, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b044056",
   "metadata": {},
   "source": [
    "### Preprocess the text using lemma_ and run the model on the preprocessed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78eae83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC Business leader remain confident Face Regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Honest Review Employees wake morning love impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike McDerment CEO FreshBooks Talks give build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>market business travel World recently amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>leverage intuition decision making feel safe r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num                                   preprocessed_txt  \n",
       "11967             0  GCC Business leader remain confident Face Regi...  \n",
       "2912              0  Honest Review Employees wake morning love impo...  \n",
       "3408              0  Mike McDerment CEO FreshBooks Talks give build...  \n",
       "502               0  market business travel World recently amazing ...  \n",
       "5279              0  leverage intuition decision making feel safe r...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['preprocessed_txt'] = df_balanced.text.apply(preprocess)\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf27a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7589     ovulate Women prefer Images Penetration Images...\n",
       "10442     scientist discover Spooky Influence Baby Choices\n",
       "8792     Olympic Race Walker step Propose boyfriend Rio...\n",
       "1733     Beloved Bipedal Bear name Pedals believe kill ...\n",
       "2526       Elizabeth Smart give Birth Baby Girl Father say\n",
       "Name: preprocessed_txt, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.preprocessed_txt,\n",
    "    df_balanced.category_num,\n",
    "    test_size= 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify=df_balanced.category_num\n",
    ")\n",
    "print(X_train.shape)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17402d77",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b4fec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e13577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we\n",
      "just\n",
      "our\n",
      "the\n",
      "part\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('we just opened our wing, the flying part is comming soon')\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff05d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_word = [token.text for token in doc if not token.is_stop]\n",
    "    return ' '.join(no_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a7067c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Musk wants time prepare trial'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Musk wants time to prepare for a trial over his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67a8a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13087, 6)\n",
      "        id                                              title  \\\n",
      "0     None       Convicted Bomb Plotter Sentenced to 30 Years   \n",
      "1  12-919   $1 Million in Restitution Payments Announced t...   \n",
      "2  11-1002  $1 Million Settlement Reached for Natural Reso...   \n",
      "3   10-015  10 Las Vegas Men Indicted \\r\\nfor Falsifying V...   \n",
      "4   18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
      "\n",
      "                                            contents  \\\n",
      "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...   \n",
      "1    WASHINGTON – North Carolina’s Waccamaw River...   \n",
      "2        BOSTON– A $1-million settlement has been...   \n",
      "3    WASHINGTON—A federal grand jury in Las Vegas...   \n",
      "4  The U.S. Department of Justice, the U.S. Envir...   \n",
      "\n",
      "                        date         topics  \\\n",
      "0  2014-10-01T00:00:00-04:00             []   \n",
      "1  2012-07-25T00:00:00-04:00             []   \n",
      "2  2011-08-03T00:00:00-04:00             []   \n",
      "3  2010-01-08T00:00:00-05:00             []   \n",
      "4  2018-07-09T00:00:00-04:00  [Environment]   \n",
      "\n",
      "                                     components  \n",
      "0            [National Security Division (NSD)]  \n",
      "1  [Environment and Natural Resources Division]  \n",
      "2  [Environment and Natural Resources Division]  \n",
      "3  [Environment and Natural Resources Division]  \n",
      "4  [Environment and Natural Resources Division]  \n",
      "Index(['id', 'title', 'contents', 'date', 'topics', 'components'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('combined.json', lines=True)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39c8ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4688, 6)\n",
      "         id                                              title  \\\n",
      "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
      "7   14-1412  14 Indicted in Connection with New England Com...   \n",
      "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
      "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
      "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
      "\n",
      "                                             contents  \\\n",
      "4   The U.S. Department of Justice, the U.S. Envir...   \n",
      "7   A 131-count criminal indictment was unsealed t...   \n",
      "19  The United States Attorney’s Office for the Mi...   \n",
      "22  21st Century Oncology LLC, has agreed to pay $...   \n",
      "23  21st Century Oncology Inc. and certain of its ...   \n",
      "\n",
      "                         date                                 topics  \\\n",
      "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
      "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
      "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
      "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
      "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
      "\n",
      "                                           components  \n",
      "4        [Environment and Natural Resources Division]  \n",
      "7                                    [Civil Division]  \n",
      "19  [Environment and Natural Resources Division, U...  \n",
      "22                                   [Civil Division]  \n",
      "23           [Civil Division, USAO - Florida, Middle]  \n"
     ]
    }
   ],
   "source": [
    "df = df[df['topics'].str.len() !=0]\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02e2705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(100)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0de2aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_contents'] = df.contents.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88832e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "      <th>new_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "      <td>U.S. Department Justice , U.S. Environmental P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>131 - count criminal indictment unsealed today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "      <td>United States Attorney Office Middle District ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>21st Century Oncology LLC , agreed pay $ 19.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "      <td>21st Century Oncology Inc. certain subsidiarie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \\\n",
       "4        [Environment and Natural Resources Division]   \n",
       "7                                    [Civil Division]   \n",
       "19  [Environment and Natural Resources Division, U...   \n",
       "22                                   [Civil Division]   \n",
       "23           [Civil Division, USAO - Florida, Middle]   \n",
       "\n",
       "                                         new_contents  \n",
       "4   U.S. Department Justice , U.S. Environmental P...  \n",
       "7   131 - count criminal indictment unsealed today...  \n",
       "19  United States Attorney Office Middle District ...  \n",
       "22  21st Century Oncology LLC , agreed pay $ 19.75...  \n",
       "23  21st Century Oncology Inc. certain subsidiarie...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7c74dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e232366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6286"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1d306a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.new_contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0903afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The U.S. Department of Justice, the U.S. Environmental Protection Agency (EPA), and the Rhode Island'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.contents[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd13ea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Department Justice , U.S. Environmental Protection Agency ( EPA ) , Rhode Island Department Env'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_contents[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ec4e7",
   "metadata": {},
   "source": [
    " Sentiment detection: Not always but in some cases, based on your dataset it can change the sentiment of a sentence if you remove stop words\n",
    "\n",
    "preprocess(\"this is a good movie\")\n",
    "\n",
    "'good movie'\n",
    "\n",
    "preprocess(\"this is not a good movie\")\n",
    "\n",
    "'good movie'\n",
    "\n",
    "(2) Language translation: Say you want to translate following sentence from english to telugu. Before actual translation if you remove stop words and then translate, it will produce horrible result\n",
    "\n",
    "preprocess(\"how are you doing dhaval?\")\n",
    "\n",
    "'dhaval ?'\n",
    "\n",
    "(3) Chat bot or any Q&A system\n",
    "\n",
    "preprocess(\"I don't find yoga mat on your website. Can you help?\")\n",
    "\n",
    "'find yoga mat website . help ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71721923",
   "metadata": {},
   "source": [
    "## Create a pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab21596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       276\n",
      "           1       0.93      0.82      0.87       277\n",
      "           2       0.81      0.91      0.86       276\n",
      "           3       0.92      0.83      0.87       276\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.86      0.86      0.86      1105\n",
      "weighted avg       0.87      0.86      0.86      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6d910",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508c582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       276\n",
      "           1       0.94      0.82      0.87       277\n",
      "           2       0.82      0.91      0.86       276\n",
      "           3       0.91      0.82      0.86       276\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.86      0.86      0.86      1105\n",
      "weighted avg       0.86      0.86      0.86      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b29e7",
   "metadata": {},
   "source": [
    "### Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bb3b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242,   7,  16,  11],\n",
       "       [ 12, 226,  33,   6],\n",
       "       [ 17,   2, 252,   5],\n",
       "       [ 37,   6,   7, 226]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44630f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6e0e204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e924b",
   "metadata": {},
   "source": [
    "## Exercise- Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118659a2",
   "metadata": {},
   "source": [
    "- In this Exercise, you are going to classify whether a given movie review is positive or negative.\n",
    "- you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "372ac257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6818e4",
   "metadata": {},
   "source": [
    "About Data: IMDB Dataset\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "- This data consists of two columns. - review - sentiment\n",
    "- Reviews are the statements given by users after watching the movie.\n",
    "- sentiment feature tells whether the given review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f71b9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "#1. read the data provided in the same directory with name 'movies_sentiment_data.csv' and store it in df variable\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "#2. print the shape of the data\n",
    "print(df.shape)\n",
    "#3. print top 5 datapoints\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33348cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  Category\n",
       "0  One of the other reviewers has mentioned that ...  positive         1\n",
       "1  A wonderful little production. <br /><br />The...  positive         1\n",
       "2  I thought this was a wonderful way to spend ti...  positive         1\n",
       "3  Basically there's a family where a little boy ...  negative         0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive         1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new column \"Category\" which represent 1 if the sentiment is positive or 0 if it is negative\n",
    "df['Category'] = df.sentiment.map({\n",
    "    'positive': 1,\n",
    "    'negative': 0\n",
    "})\n",
    "\n",
    "# Or\n",
    "df['Category'] = df['sentiment'].apply(lambda x:1 if x=='positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9c22ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of 'Category' and see whether the Target labels are balanced or not.\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e7e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33683    Let me start out by saying this movie has 1 fu...\n",
       "40435    When tradition dictates that an artist must pa...\n",
       "32990    At the end, it is clear that the murderers pla...\n",
       "40181    J.S. Cardone directed a little known 'Video Na...\n",
       "35795    Wow, I can't believe i'm the first and only on...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do the 'train-test' splitting with test size of 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(    \n",
    "    df.review,\n",
    "    df.Category,\n",
    "    test_size= 0.2,\n",
    "    random_state = 2022, #Sets a fixed seed so that the split is reproducible (you get the same split every time you run it).\n",
    "    stratify=df.Category #Ensures that the class distribution in the training and test sets\n",
    "                        #is the same as in the original dataset. This is especially important for imbalanced classes.\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c38cf",
   "metadata": {},
   "source": [
    "\n",
    "#### use CountVectorizer for pre-processing the text.\n",
    "\n",
    "use Random Forest as the classifier with estimators as 50 and criterion as entropy.\n",
    "\n",
    "print the classification report.\n",
    "\n",
    "References:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a71588d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      5000\n",
      "           1       0.83      0.83      0.83      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer()),\n",
    "    ('rf_classifier', RandomForestClassifier(n_estimators=50, criterion='entropy'))\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a118fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      5000\n",
      "           1       0.84      0.85      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer()),\n",
    "    ('rf_classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba321b",
   "metadata": {},
   "source": [
    "## Exercise-2\n",
    "\n",
    "using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "Note:\n",
    "\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean'.\n",
    "- print the classification report.\n",
    "References:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4dccab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.59      5000\n",
      "           1       0.60      0.66      0.63      5000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.61      0.61      0.61     10000\n",
      "weighted avg       0.61      0.61      0.61     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def preprocess(text):\n",
    "#     doc = nlp(text)\n",
    "#     filtered_tokens = []\n",
    "#     for token in doc:\n",
    "#         if token.is_stop or token.is_punct:\n",
    "#             continue\n",
    "#         filtered_tokens.append(token.lemma_)\n",
    "#     return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('kn_classifier', KNeighborsClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9360cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      5000\n",
      "           1       0.65      0.65      0.65      5000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.65     10000\n",
      "weighted avg       0.65      0.65      0.65     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer()),\n",
    "    ('kn_classifier', KNeighborsClassifier(n_neighbors=10, metric = 'euclidean'))\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77d3415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      5000\n",
      "           1       0.89      0.86      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('nb_classifier', MultinomialNB())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151d7fd",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "What is TF-IDF?\n",
    "\n",
    "TF stands for Term Frequency and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
    "\n",
    "   Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
    "Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "IDF stands for Inverse Document Frequency and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "   Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
    "In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
    "\n",
    "Finally:\n",
    "\n",
    "   TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a697379",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Humans 👦 show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    "\n",
    "In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    "\n",
    "For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    "\n",
    "We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms.\n",
    "\n",
    "About Data: Emotion Detection\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "This data consists of two columns. - Comment - Emotion\n",
    "\n",
    "Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "Emotion feature tells whether the given comment is fear 😨, Anger 😡, Joy 😂.\n",
    "\n",
    "As there are only 3 classes, this problem comes under the Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa6bf0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/codebasics/nlp-tutorials/800619f7ee7dafa941c09b9395903c8995df12e7/12_tf_idf/Emotion_classify_Data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b75ab104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2e22b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num\n",
       "0  i seriously hate one subject to death but now ...    fear            1\n",
       "1                 im so full of life i feel appalled   anger            2\n",
       "2  i sit here to write i start to dig out my feel...    fear            1\n",
       "3  ive been really angry with r and i feel like a...     joy            0\n",
       "4  i feel suspicious if there is no one outside l...    fear            1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "df['Emotion_num'] = df.Emotion.map({\n",
    "    'joy': 0,\n",
    "    'fear':1,\n",
    "    'anger':2\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb03ef",
   "metadata": {},
   "source": [
    "#### Modelling without Pre-processing Text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f67b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749,)\n",
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "#import train-test split\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "#Note: Give Random state 2022 and also do the stratify sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Comment,\n",
    "    df.Emotion_num,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=df.Emotion_num\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024b8e6",
   "metadata": {},
   "source": [
    "#### Attempt 1 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e5cbf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       400\n",
      "           1       0.95      0.86      0.90       388\n",
      "           2       0.93      0.84      0.89       400\n",
      "\n",
      "    accuracy                           0.89      1188\n",
      "   macro avg       0.90      0.89      0.89      1188\n",
      "weighted avg       0.90      0.89      0.89      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vecotr', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('rf_classifier', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc143334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       400\n",
      "           1       0.95      0.87      0.90       388\n",
      "           2       0.93      0.89      0.91       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.91      0.90      0.90      1188\n",
      "weighted avg       0.91      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotr', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('rf_classifier', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "598e4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       400\n",
      "           1       0.93      0.90      0.91       388\n",
      "           2       0.93      0.90      0.91       400\n",
      "\n",
      "    accuracy                           0.92      1188\n",
      "   macro avg       0.92      0.92      0.92      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotr', CountVectorizer()),\n",
    "    ('rf_classifier', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207724e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.87      0.83      0.85       388\n",
      "           2       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.86      1188\n",
      "   macro avg       0.86      0.86      0.86      1188\n",
      "weighted avg       0.86      0.86      0.86      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotr', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8965c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       400\n",
      "           1       0.86      0.88      0.87       388\n",
      "           2       0.85      0.88      0.87       400\n",
      "\n",
      "    accuracy                           0.87      1188\n",
      "   macro avg       0.87      0.87      0.87      1188\n",
      "weighted avg       0.87      0.87      0.87      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotr', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79881ef6",
   "metadata": {},
   "source": [
    "#### Attempt 4 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "Note:\n",
    "\n",
    "using TF-IDF vectorizer for Pre-processing the text.\n",
    "use RandomForest as the classifier.\n",
    "print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86202fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92       400\n",
      "           1       0.91      0.89      0.90       388\n",
      "           2       0.94      0.87      0.91       400\n",
      "\n",
      "    accuracy                           0.91      1188\n",
      "   macro avg       0.91      0.91      0.91      1188\n",
      "weighted avg       0.91      0.91      0.91      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "clf = Pipeline([\n",
    "    ('tf-idfvecotr', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0b0f0",
   "metadata": {},
   "source": [
    "Use text pre-processing to remove stop words, punctuations and apply lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "588804b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['new_comment'] = df.Comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd7e9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>seriously hate subject death feel reluctant drop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "      <td>m life feel appalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>sit write start dig feeling think afraid accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>ve angry r feel like idiot trust place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>feel suspicious outside like rapture happen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num  \\\n",
       "0  i seriously hate one subject to death but now ...    fear            1   \n",
       "1                 im so full of life i feel appalled   anger            2   \n",
       "2  i sit here to write i start to dig out my feel...    fear            1   \n",
       "3  ive been really angry with r and i feel like a...     joy            0   \n",
       "4  i feel suspicious if there is no one outside l...    fear            1   \n",
       "\n",
       "                                         new_comment  \n",
       "0   seriously hate subject death feel reluctant drop  \n",
       "1                               m life feel appalled  \n",
       "2  sit write start dig feeling think afraid accep...  \n",
       "3             ve angry r feel like idiot trust place  \n",
       "4        feel suspicious outside like rapture happen  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "14eb4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749,)\n",
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.new_comment,\n",
    "    df.Emotion_num,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=df.Emotion_num\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3eee7772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       400\n",
      "           1       0.94      0.92      0.93       388\n",
      "           2       0.94      0.91      0.92       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "clf = Pipeline([\n",
    "    ('tf-idfvecotr', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
